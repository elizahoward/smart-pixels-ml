{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df51370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running scheduler: const_1e-3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Quantization is False in data generator. This may affect model performance.\n",
      "WARNING:root:Quantization is False in data generator. This may affect model performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - accuracy: 0.4312 - loss: 1.6461 - val_accuracy: 0.5964 - val_loss: 1.0623\n",
      "Epoch 2/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.3660 - loss: 1.2905 - val_accuracy: 0.6413 - val_loss: 0.7171\n",
      "Epoch 3/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5312 - loss: 0.8708 - val_accuracy: 0.6569 - val_loss: 0.6978\n",
      "Epoch 4/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5200 - loss: 0.8621 - val_accuracy: 0.6629 - val_loss: 0.6799\n",
      "Epoch 5/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5263 - loss: 0.8339 - val_accuracy: 0.6669 - val_loss: 0.6645\n",
      "Epoch 6/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5368 - loss: 0.8081 - val_accuracy: 0.6728 - val_loss: 0.6527\n",
      "Epoch 7/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.5492 - loss: 0.7867 - val_accuracy: 0.6738 - val_loss: 0.6458\n",
      "Epoch 8/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.5519 - loss: 0.7745 - val_accuracy: 0.6736 - val_loss: 0.6373\n",
      "Epoch 9/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.5565 - loss: 0.7595 - val_accuracy: 0.6732 - val_loss: 0.6301\n",
      "Epoch 10/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5575 - loss: 0.7450 - val_accuracy: 0.6757 - val_loss: 0.6256\n",
      "Epoch 11/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5574 - loss: 0.7369 - val_accuracy: 0.6772 - val_loss: 0.6219\n",
      "Epoch 12/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5603 - loss: 0.7286 - val_accuracy: 0.6785 - val_loss: 0.6192\n",
      "Epoch 13/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5612 - loss: 0.7234 - val_accuracy: 0.6790 - val_loss: 0.6156\n",
      "Epoch 14/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5627 - loss: 0.7169 - val_accuracy: 0.6810 - val_loss: 0.6132\n",
      "Epoch 15/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5644 - loss: 0.7120 - val_accuracy: 0.6805 - val_loss: 0.6111\n",
      "Epoch 16/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5664 - loss: 0.7070 - val_accuracy: 0.6800 - val_loss: 0.6091\n",
      "Epoch 17/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5680 - loss: 0.7027 - val_accuracy: 0.6803 - val_loss: 0.6070\n",
      "Epoch 18/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5689 - loss: 0.6983 - val_accuracy: 0.6798 - val_loss: 0.6052\n",
      "Epoch 19/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.5700 - loss: 0.6941 - val_accuracy: 0.6804 - val_loss: 0.6036\n",
      "Epoch 20/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5708 - loss: 0.6904 - val_accuracy: 0.6807 - val_loss: 0.6025\n",
      "Epoch 21/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.5712 - loss: 0.6876 - val_accuracy: 0.6817 - val_loss: 0.6013\n",
      "Epoch 22/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.5728 - loss: 0.6845 - val_accuracy: 0.6817 - val_loss: 0.6000\n",
      "Epoch 23/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5734 - loss: 0.6818 - val_accuracy: 0.6819 - val_loss: 0.5990\n",
      "Epoch 24/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5746 - loss: 0.6787 - val_accuracy: 0.6817 - val_loss: 0.5981\n",
      "Epoch 25/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5747 - loss: 0.6770 - val_accuracy: 0.6822 - val_loss: 0.5968\n",
      "Epoch 26/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5770 - loss: 0.6727 - val_accuracy: 0.6818 - val_loss: 0.5963\n",
      "Epoch 27/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5763 - loss: 0.6721 - val_accuracy: 0.6830 - val_loss: 0.5951\n",
      "Epoch 28/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5777 - loss: 0.6681 - val_accuracy: 0.6829 - val_loss: 0.5941\n",
      "Epoch 29/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5790 - loss: 0.6662 - val_accuracy: 0.6828 - val_loss: 0.5933\n",
      "Epoch 30/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5810 - loss: 0.6642 - val_accuracy: 0.6832 - val_loss: 0.5926\n",
      "Epoch 31/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5820 - loss: 0.6623 - val_accuracy: 0.6832 - val_loss: 0.5918\n",
      "Epoch 32/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5828 - loss: 0.6606 - val_accuracy: 0.6837 - val_loss: 0.5909\n",
      "Epoch 33/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5838 - loss: 0.6585 - val_accuracy: 0.6844 - val_loss: 0.5901\n",
      "Epoch 34/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5854 - loss: 0.6564 - val_accuracy: 0.6842 - val_loss: 0.5894\n",
      "Epoch 35/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.5866 - loss: 0.6544 - val_accuracy: 0.6845 - val_loss: 0.5888\n",
      "Epoch 36/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.5872 - loss: 0.6527 - val_accuracy: 0.6857 - val_loss: 0.5882\n",
      "Epoch 37/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5878 - loss: 0.6511 - val_accuracy: 0.6855 - val_loss: 0.5877\n",
      "Epoch 38/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5881 - loss: 0.6496 - val_accuracy: 0.6858 - val_loss: 0.5872\n",
      "Epoch 39/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5886 - loss: 0.6482 - val_accuracy: 0.6861 - val_loss: 0.5868\n",
      "Epoch 40/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5888 - loss: 0.6469 - val_accuracy: 0.6863 - val_loss: 0.5863\n",
      "Epoch 41/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5887 - loss: 0.6455 - val_accuracy: 0.6865 - val_loss: 0.5859\n",
      "Epoch 42/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5885 - loss: 0.6443 - val_accuracy: 0.6870 - val_loss: 0.5854\n",
      "Epoch 43/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5887 - loss: 0.6428 - val_accuracy: 0.6868 - val_loss: 0.5851\n",
      "Epoch 44/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5882 - loss: 0.6417 - val_accuracy: 0.6880 - val_loss: 0.5845\n",
      "Epoch 45/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5893 - loss: 0.6401 - val_accuracy: 0.6874 - val_loss: 0.5842\n",
      "Epoch 46/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5878 - loss: 0.6394 - val_accuracy: 0.6880 - val_loss: 0.5836\n",
      "Epoch 47/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5901 - loss: 0.6374 - val_accuracy: 0.6874 - val_loss: 0.5834\n",
      "Epoch 48/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5885 - loss: 0.6372 - val_accuracy: 0.6881 - val_loss: 0.5830\n",
      "Epoch 49/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.5910 - loss: 0.6351 - val_accuracy: 0.6877 - val_loss: 0.5829\n",
      "Epoch 50/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5896 - loss: 0.6351 - val_accuracy: 0.6884 - val_loss: 0.5823\n",
      "Epoch 51/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5914 - loss: 0.6329 - val_accuracy: 0.6883 - val_loss: 0.5823\n",
      "Epoch 52/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.5902 - loss: 0.6332 - val_accuracy: 0.6884 - val_loss: 0.5816\n",
      "Epoch 53/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.5922 - loss: 0.6307 - val_accuracy: 0.6883 - val_loss: 0.5816\n",
      "Epoch 54/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.5906 - loss: 0.6310 - val_accuracy: 0.6886 - val_loss: 0.5811\n",
      "Epoch 55/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.5932 - loss: 0.6286 - val_accuracy: 0.6883 - val_loss: 0.5810\n",
      "Epoch 56/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5915 - loss: 0.6286 - val_accuracy: 0.6882 - val_loss: 0.5804\n",
      "Epoch 57/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5940 - loss: 0.6261 - val_accuracy: 0.6880 - val_loss: 0.5802\n",
      "Epoch 58/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5925 - loss: 0.6258 - val_accuracy: 0.6883 - val_loss: 0.5798\n",
      "Epoch 59/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5949 - loss: 0.6237 - val_accuracy: 0.6878 - val_loss: 0.5797\n",
      "Epoch 60/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5933 - loss: 0.6234 - val_accuracy: 0.6886 - val_loss: 0.5794\n",
      "Epoch 61/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5956 - loss: 0.6216 - val_accuracy: 0.6879 - val_loss: 0.5792\n",
      "Epoch 62/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5941 - loss: 0.6213 - val_accuracy: 0.6886 - val_loss: 0.5789\n",
      "Epoch 63/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.5957 - loss: 0.6197 - val_accuracy: 0.6873 - val_loss: 0.5789\n",
      "Epoch 64/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.5951 - loss: 0.6197 - val_accuracy: 0.6886 - val_loss: 0.5784\n",
      "Epoch 65/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5975 - loss: 0.6178 - val_accuracy: 0.6876 - val_loss: 0.5784\n",
      "Epoch 66/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5967 - loss: 0.6176 - val_accuracy: 0.6881 - val_loss: 0.5780\n",
      "Epoch 67/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5983 - loss: 0.6161 - val_accuracy: 0.6881 - val_loss: 0.5780\n",
      "Epoch 68/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.5978 - loss: 0.6156 - val_accuracy: 0.6884 - val_loss: 0.5776\n",
      "Epoch 69/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.5992 - loss: 0.6143 - val_accuracy: 0.6886 - val_loss: 0.5776\n",
      "Epoch 70/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.5991 - loss: 0.6138 - val_accuracy: 0.6891 - val_loss: 0.5771\n",
      "Epoch 71/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - accuracy: 0.6006 - loss: 0.6124 - val_accuracy: 0.6885 - val_loss: 0.5771\n",
      "Epoch 72/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - accuracy: 0.6016 - loss: 0.6117 - val_accuracy: 0.6881 - val_loss: 0.5769\n",
      "Epoch 73/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.6030 - loss: 0.6105 - val_accuracy: 0.6889 - val_loss: 0.5767\n",
      "Epoch 74/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.6038 - loss: 0.6097 - val_accuracy: 0.6890 - val_loss: 0.5764\n",
      "Epoch 75/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.6035 - loss: 0.6091 - val_accuracy: 0.6889 - val_loss: 0.5762\n",
      "Epoch 76/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.6055 - loss: 0.6082 - val_accuracy: 0.6895 - val_loss: 0.5760\n",
      "Epoch 77/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.6067 - loss: 0.6076 - val_accuracy: 0.6895 - val_loss: 0.5759\n",
      "Epoch 78/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.6076 - loss: 0.6067 - val_accuracy: 0.6898 - val_loss: 0.5758\n",
      "Epoch 79/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.6083 - loss: 0.6063 - val_accuracy: 0.6896 - val_loss: 0.5755\n",
      "Epoch 80/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.6086 - loss: 0.6054 - val_accuracy: 0.6891 - val_loss: 0.5754\n",
      "Epoch 81/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.6096 - loss: 0.6048 - val_accuracy: 0.6885 - val_loss: 0.5752\n",
      "Epoch 82/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.6096 - loss: 0.6043 - val_accuracy: 0.6890 - val_loss: 0.5751\n",
      "Epoch 83/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.6114 - loss: 0.6034 - val_accuracy: 0.6888 - val_loss: 0.5749\n",
      "Epoch 84/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.6108 - loss: 0.6031 - val_accuracy: 0.6891 - val_loss: 0.5747\n",
      "Epoch 85/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.6125 - loss: 0.6022 - val_accuracy: 0.6888 - val_loss: 0.5745\n",
      "Epoch 86/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - accuracy: 0.6122 - loss: 0.6018 - val_accuracy: 0.6890 - val_loss: 0.5744\n",
      "Epoch 87/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.6134 - loss: 0.6007 - val_accuracy: 0.6891 - val_loss: 0.5740\n",
      "Epoch 88/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.6138 - loss: 0.6001 - val_accuracy: 0.6887 - val_loss: 0.5740\n",
      "Epoch 89/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.6147 - loss: 0.5993 - val_accuracy: 0.6890 - val_loss: 0.5738\n",
      "Epoch 90/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.6153 - loss: 0.5983 - val_accuracy: 0.6891 - val_loss: 0.5736\n",
      "Epoch 91/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.6151 - loss: 0.5979 - val_accuracy: 0.6893 - val_loss: 0.5735\n",
      "Epoch 92/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.6157 - loss: 0.5971 - val_accuracy: 0.6894 - val_loss: 0.5733\n",
      "Epoch 93/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.6159 - loss: 0.5966 - val_accuracy: 0.6894 - val_loss: 0.5731\n",
      "Epoch 94/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.6170 - loss: 0.5961 - val_accuracy: 0.6896 - val_loss: 0.5729\n",
      "Epoch 95/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.6173 - loss: 0.5953 - val_accuracy: 0.6894 - val_loss: 0.5729\n",
      "Epoch 96/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.6181 - loss: 0.5950 - val_accuracy: 0.6900 - val_loss: 0.5726\n",
      "Epoch 97/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.6189 - loss: 0.5942 - val_accuracy: 0.6899 - val_loss: 0.5724\n",
      "Epoch 98/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.6191 - loss: 0.5935 - val_accuracy: 0.6902 - val_loss: 0.5722\n",
      "Epoch 99/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.6197 - loss: 0.5930 - val_accuracy: 0.6899 - val_loss: 0.5722\n",
      "Epoch 100/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.6203 - loss: 0.5923 - val_accuracy: 0.6897 - val_loss: 0.5718\n",
      "Epoch 101/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.6206 - loss: 0.5919 - val_accuracy: 0.6897 - val_loss: 0.5717\n",
      "Epoch 102/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.6217 - loss: 0.5908 - val_accuracy: 0.6896 - val_loss: 0.5716\n",
      "Epoch 103/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.6216 - loss: 0.5905 - val_accuracy: 0.6894 - val_loss: 0.5714\n",
      "Epoch 104/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.6230 - loss: 0.5896 - val_accuracy: 0.6895 - val_loss: 0.5713\n",
      "Epoch 105/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.6232 - loss: 0.5894 - val_accuracy: 0.6897 - val_loss: 0.5711\n",
      "Epoch 106/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.6242 - loss: 0.5882 - val_accuracy: 0.6899 - val_loss: 0.5708\n",
      "Epoch 107/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.6244 - loss: 0.5880 - val_accuracy: 0.6903 - val_loss: 0.5708\n",
      "Epoch 108/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.6250 - loss: 0.5872 - val_accuracy: 0.6900 - val_loss: 0.5706\n",
      "Epoch 109/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.6254 - loss: 0.5871 - val_accuracy: 0.6910 - val_loss: 0.5704\n",
      "Epoch 110/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.6267 - loss: 0.5858 - val_accuracy: 0.6898 - val_loss: 0.5705\n",
      "Epoch 111/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.6255 - loss: 0.5863 - val_accuracy: 0.6903 - val_loss: 0.5701\n",
      "Epoch 112/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.6284 - loss: 0.5847 - val_accuracy: 0.6902 - val_loss: 0.5704\n",
      "Epoch 113/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.6261 - loss: 0.5852 - val_accuracy: 0.6903 - val_loss: 0.5698\n",
      "Epoch 114/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.6298 - loss: 0.5838 - val_accuracy: 0.6906 - val_loss: 0.5702\n",
      "Epoch 115/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.6278 - loss: 0.5840 - val_accuracy: 0.6904 - val_loss: 0.5697\n",
      "Epoch 116/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.6306 - loss: 0.5822 - val_accuracy: 0.6909 - val_loss: 0.5699\n",
      "Epoch 117/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.6289 - loss: 0.5823 - val_accuracy: 0.6903 - val_loss: 0.5696\n",
      "Epoch 118/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.6317 - loss: 0.5811 - val_accuracy: 0.6906 - val_loss: 0.5697\n",
      "Epoch 119/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.6299 - loss: 0.5817 - val_accuracy: 0.6909 - val_loss: 0.5694\n",
      "Epoch 120/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.6322 - loss: 0.5800 - val_accuracy: 0.6909 - val_loss: 0.5692\n",
      "Completed: const_1e-3\n",
      "\n",
      "=== Running scheduler: const_1e-4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Quantization is False in data generator. This may affect model performance.\n",
      "WARNING:root:Quantization is False in data generator. This may affect model performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - accuracy: 0.5655 - loss: 0.9844 - val_accuracy: 0.6371 - val_loss: 0.8069\n",
      "Epoch 2/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5895 - loss: 0.8685 - val_accuracy: 0.6500 - val_loss: 0.7490\n",
      "Epoch 3/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6230 - loss: 0.7884 - val_accuracy: 0.6498 - val_loss: 0.7117\n",
      "Epoch 4/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6320 - loss: 0.7376 - val_accuracy: 0.6514 - val_loss: 0.6862\n",
      "Epoch 5/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.6368 - loss: 0.7042 - val_accuracy: 0.6540 - val_loss: 0.6676\n",
      "Epoch 6/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.6391 - loss: 0.6818 - val_accuracy: 0.6549 - val_loss: 0.6541\n",
      "Epoch 7/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 129ms/step - accuracy: 0.6407 - loss: 0.6663 - val_accuracy: 0.6574 - val_loss: 0.6444\n",
      "Epoch 8/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.6422 - loss: 0.6557 - val_accuracy: 0.6581 - val_loss: 0.6372\n",
      "Epoch 9/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.6433 - loss: 0.6478 - val_accuracy: 0.6595 - val_loss: 0.6316\n",
      "Epoch 10/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.6440 - loss: 0.6416 - val_accuracy: 0.6603 - val_loss: 0.6272\n",
      "Epoch 11/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 138ms/step - accuracy: 0.6443 - loss: 0.6367 - val_accuracy: 0.6628 - val_loss: 0.6236\n",
      "Epoch 12/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.6451 - loss: 0.6328 - val_accuracy: 0.6648 - val_loss: 0.6206\n",
      "Epoch 13/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - accuracy: 0.6460 - loss: 0.6295 - val_accuracy: 0.6666 - val_loss: 0.6182\n",
      "Epoch 14/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - accuracy: 0.6458 - loss: 0.6266 - val_accuracy: 0.6675 - val_loss: 0.6162\n",
      "Epoch 15/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - accuracy: 0.6456 - loss: 0.6242 - val_accuracy: 0.6676 - val_loss: 0.6143\n",
      "Epoch 16/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - accuracy: 0.6458 - loss: 0.6221 - val_accuracy: 0.6685 - val_loss: 0.6127\n",
      "Epoch 17/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 130ms/step - accuracy: 0.6457 - loss: 0.6201 - val_accuracy: 0.6687 - val_loss: 0.6113\n",
      "Epoch 18/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - accuracy: 0.6462 - loss: 0.6183 - val_accuracy: 0.6684 - val_loss: 0.6100\n",
      "Epoch 19/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 142ms/step - accuracy: 0.6464 - loss: 0.6168 - val_accuracy: 0.6691 - val_loss: 0.6088\n",
      "Epoch 20/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 138ms/step - accuracy: 0.6473 - loss: 0.6153 - val_accuracy: 0.6695 - val_loss: 0.6077\n",
      "Epoch 21/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - accuracy: 0.6474 - loss: 0.6140 - val_accuracy: 0.6689 - val_loss: 0.6067\n",
      "Epoch 22/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - accuracy: 0.6476 - loss: 0.6127 - val_accuracy: 0.6692 - val_loss: 0.6058\n",
      "Epoch 23/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 131ms/step - accuracy: 0.6475 - loss: 0.6116 - val_accuracy: 0.6698 - val_loss: 0.6049\n",
      "Epoch 24/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 139ms/step - accuracy: 0.6475 - loss: 0.6105 - val_accuracy: 0.6695 - val_loss: 0.6041\n",
      "Epoch 25/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - accuracy: 0.6475 - loss: 0.6096 - val_accuracy: 0.6702 - val_loss: 0.6033\n",
      "Epoch 26/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - accuracy: 0.6476 - loss: 0.6086 - val_accuracy: 0.6710 - val_loss: 0.6025\n",
      "Epoch 27/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - accuracy: 0.6481 - loss: 0.6077 - val_accuracy: 0.6713 - val_loss: 0.6018\n",
      "Epoch 28/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - accuracy: 0.6488 - loss: 0.6069 - val_accuracy: 0.6718 - val_loss: 0.6011\n",
      "Epoch 29/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - accuracy: 0.6493 - loss: 0.6061 - val_accuracy: 0.6713 - val_loss: 0.6005\n",
      "Epoch 30/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 132ms/step - accuracy: 0.6499 - loss: 0.6054 - val_accuracy: 0.6722 - val_loss: 0.5998\n",
      "Epoch 31/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - accuracy: 0.6501 - loss: 0.6047 - val_accuracy: 0.6724 - val_loss: 0.5993\n",
      "Epoch 32/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - accuracy: 0.6502 - loss: 0.6041 - val_accuracy: 0.6730 - val_loss: 0.5987\n",
      "Epoch 33/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - accuracy: 0.6501 - loss: 0.6034 - val_accuracy: 0.6736 - val_loss: 0.5982\n",
      "Epoch 34/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 140ms/step - accuracy: 0.6503 - loss: 0.6028 - val_accuracy: 0.6733 - val_loss: 0.5977\n",
      "Epoch 35/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 130ms/step - accuracy: 0.6503 - loss: 0.6023 - val_accuracy: 0.6733 - val_loss: 0.5972\n",
      "Epoch 36/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - accuracy: 0.6505 - loss: 0.6016 - val_accuracy: 0.6734 - val_loss: 0.5967\n",
      "Epoch 37/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 131ms/step - accuracy: 0.6507 - loss: 0.6011 - val_accuracy: 0.6733 - val_loss: 0.5963\n",
      "Epoch 38/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - accuracy: 0.6509 - loss: 0.6005 - val_accuracy: 0.6739 - val_loss: 0.5958\n",
      "Epoch 39/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - accuracy: 0.6508 - loss: 0.6001 - val_accuracy: 0.6737 - val_loss: 0.5954\n",
      "Epoch 40/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 140ms/step - accuracy: 0.6509 - loss: 0.5996 - val_accuracy: 0.6737 - val_loss: 0.5950\n",
      "Epoch 41/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 137ms/step - accuracy: 0.6509 - loss: 0.5992 - val_accuracy: 0.6737 - val_loss: 0.5946\n",
      "Epoch 42/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - accuracy: 0.6507 - loss: 0.5987 - val_accuracy: 0.6742 - val_loss: 0.5943\n",
      "Epoch 43/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 130ms/step - accuracy: 0.6511 - loss: 0.5983 - val_accuracy: 0.6745 - val_loss: 0.5939\n",
      "Epoch 44/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - accuracy: 0.6513 - loss: 0.5978 - val_accuracy: 0.6745 - val_loss: 0.5936\n",
      "Epoch 45/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 132ms/step - accuracy: 0.6510 - loss: 0.5974 - val_accuracy: 0.6748 - val_loss: 0.5932\n",
      "Epoch 46/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - accuracy: 0.6509 - loss: 0.5970 - val_accuracy: 0.6750 - val_loss: 0.5929\n",
      "Epoch 47/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - accuracy: 0.6512 - loss: 0.5966 - val_accuracy: 0.6753 - val_loss: 0.5926\n",
      "Epoch 48/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 130ms/step - accuracy: 0.6512 - loss: 0.5962 - val_accuracy: 0.6756 - val_loss: 0.5922\n",
      "Epoch 49/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - accuracy: 0.6513 - loss: 0.5958 - val_accuracy: 0.6759 - val_loss: 0.5920\n",
      "Epoch 50/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 139ms/step - accuracy: 0.6512 - loss: 0.5954 - val_accuracy: 0.6756 - val_loss: 0.5917\n",
      "Epoch 51/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 131ms/step - accuracy: 0.6513 - loss: 0.5951 - val_accuracy: 0.6759 - val_loss: 0.5914\n",
      "Epoch 52/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - accuracy: 0.6510 - loss: 0.5947 - val_accuracy: 0.6762 - val_loss: 0.5911\n",
      "Epoch 53/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 129ms/step - accuracy: 0.6513 - loss: 0.5944 - val_accuracy: 0.6764 - val_loss: 0.5908\n",
      "Epoch 54/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - accuracy: 0.6510 - loss: 0.5941 - val_accuracy: 0.6763 - val_loss: 0.5905\n",
      "Epoch 55/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - accuracy: 0.6512 - loss: 0.5937 - val_accuracy: 0.6765 - val_loss: 0.5903\n",
      "Epoch 56/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - accuracy: 0.6511 - loss: 0.5934 - val_accuracy: 0.6768 - val_loss: 0.5900\n",
      "Epoch 57/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 129ms/step - accuracy: 0.6514 - loss: 0.5931 - val_accuracy: 0.6767 - val_loss: 0.5898\n",
      "Epoch 58/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - accuracy: 0.6513 - loss: 0.5927 - val_accuracy: 0.6768 - val_loss: 0.5895\n",
      "Epoch 59/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.6513 - loss: 0.5925 - val_accuracy: 0.6768 - val_loss: 0.5893\n",
      "Epoch 60/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.6511 - loss: 0.5922 - val_accuracy: 0.6768 - val_loss: 0.5890\n",
      "Epoch 61/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 125ms/step - accuracy: 0.6512 - loss: 0.5920 - val_accuracy: 0.6772 - val_loss: 0.5888\n",
      "Epoch 62/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 126ms/step - accuracy: 0.6512 - loss: 0.5917 - val_accuracy: 0.6775 - val_loss: 0.5886\n",
      "Epoch 63/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - accuracy: 0.6514 - loss: 0.5915 - val_accuracy: 0.6776 - val_loss: 0.5884\n",
      "Epoch 64/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.6516 - loss: 0.5912 - val_accuracy: 0.6777 - val_loss: 0.5881\n",
      "Epoch 65/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.6515 - loss: 0.5909 - val_accuracy: 0.6779 - val_loss: 0.5879\n",
      "Epoch 66/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 127ms/step - accuracy: 0.6516 - loss: 0.5907 - val_accuracy: 0.6780 - val_loss: 0.5877\n",
      "Epoch 67/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - accuracy: 0.6518 - loss: 0.5904 - val_accuracy: 0.6784 - val_loss: 0.5875\n",
      "Epoch 68/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - accuracy: 0.6520 - loss: 0.5902 - val_accuracy: 0.6787 - val_loss: 0.5873\n",
      "Epoch 69/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - accuracy: 0.6521 - loss: 0.5899 - val_accuracy: 0.6791 - val_loss: 0.5871\n",
      "Epoch 70/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.6520 - loss: 0.5897 - val_accuracy: 0.6798 - val_loss: 0.5869\n",
      "Epoch 71/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.6520 - loss: 0.5894 - val_accuracy: 0.6802 - val_loss: 0.5868\n",
      "Epoch 72/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.6522 - loss: 0.5892 - val_accuracy: 0.6807 - val_loss: 0.5866\n",
      "Epoch 73/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - accuracy: 0.6522 - loss: 0.5890 - val_accuracy: 0.6810 - val_loss: 0.5864\n",
      "Epoch 74/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - accuracy: 0.6521 - loss: 0.5888 - val_accuracy: 0.6808 - val_loss: 0.5862\n",
      "Epoch 75/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.6521 - loss: 0.5885 - val_accuracy: 0.6813 - val_loss: 0.5861\n",
      "Epoch 76/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - accuracy: 0.6521 - loss: 0.5882 - val_accuracy: 0.6814 - val_loss: 0.5859\n",
      "Epoch 77/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 126ms/step - accuracy: 0.6522 - loss: 0.5881 - val_accuracy: 0.6816 - val_loss: 0.5857\n",
      "Epoch 78/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.6521 - loss: 0.5880 - val_accuracy: 0.6819 - val_loss: 0.5856\n",
      "Epoch 79/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - accuracy: 0.6521 - loss: 0.5877 - val_accuracy: 0.6823 - val_loss: 0.5854\n",
      "Epoch 80/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.6523 - loss: 0.5875 - val_accuracy: 0.6825 - val_loss: 0.5853\n",
      "Epoch 81/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - accuracy: 0.6521 - loss: 0.5873 - val_accuracy: 0.6823 - val_loss: 0.5851\n",
      "Epoch 82/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 126ms/step - accuracy: 0.6519 - loss: 0.5871 - val_accuracy: 0.6828 - val_loss: 0.5850\n",
      "Epoch 83/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 127ms/step - accuracy: 0.6520 - loss: 0.5870 - val_accuracy: 0.6825 - val_loss: 0.5848\n",
      "Epoch 84/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - accuracy: 0.6520 - loss: 0.5868 - val_accuracy: 0.6826 - val_loss: 0.5847\n",
      "Epoch 85/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - accuracy: 0.6521 - loss: 0.5866 - val_accuracy: 0.6825 - val_loss: 0.5845\n",
      "Epoch 86/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.6526 - loss: 0.5864 - val_accuracy: 0.6830 - val_loss: 0.5844\n",
      "Epoch 87/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - accuracy: 0.6526 - loss: 0.5862 - val_accuracy: 0.6831 - val_loss: 0.5842\n",
      "Epoch 88/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 0.6528 - loss: 0.5860 - val_accuracy: 0.6834 - val_loss: 0.5841\n",
      "Epoch 89/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - accuracy: 0.6529 - loss: 0.5858 - val_accuracy: 0.6834 - val_loss: 0.5840\n",
      "Epoch 90/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - accuracy: 0.6529 - loss: 0.5856 - val_accuracy: 0.6838 - val_loss: 0.5838\n",
      "Epoch 91/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.6527 - loss: 0.5854 - val_accuracy: 0.6838 - val_loss: 0.5837\n",
      "Epoch 92/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - accuracy: 0.6529 - loss: 0.5853 - val_accuracy: 0.6837 - val_loss: 0.5836\n",
      "Epoch 93/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - accuracy: 0.6530 - loss: 0.5851 - val_accuracy: 0.6838 - val_loss: 0.5835\n",
      "Epoch 94/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - accuracy: 0.6528 - loss: 0.5850 - val_accuracy: 0.6838 - val_loss: 0.5833\n",
      "Epoch 95/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 0.6529 - loss: 0.5848 - val_accuracy: 0.6837 - val_loss: 0.5832\n",
      "Epoch 96/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 0.6529 - loss: 0.5846 - val_accuracy: 0.6837 - val_loss: 0.5831\n",
      "Epoch 97/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.6528 - loss: 0.5844 - val_accuracy: 0.6834 - val_loss: 0.5829\n",
      "Epoch 98/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - accuracy: 0.6529 - loss: 0.5843 - val_accuracy: 0.6837 - val_loss: 0.5828\n",
      "Epoch 99/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 0.6528 - loss: 0.5842 - val_accuracy: 0.6838 - val_loss: 0.5827\n",
      "Epoch 100/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - accuracy: 0.6529 - loss: 0.5840 - val_accuracy: 0.6840 - val_loss: 0.5826\n",
      "Epoch 101/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 0.6528 - loss: 0.5839 - val_accuracy: 0.6841 - val_loss: 0.5824\n",
      "Epoch 102/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - accuracy: 0.6529 - loss: 0.5836 - val_accuracy: 0.6840 - val_loss: 0.5823\n",
      "Epoch 103/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.6530 - loss: 0.5835 - val_accuracy: 0.6841 - val_loss: 0.5822\n",
      "Epoch 104/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - accuracy: 0.6530 - loss: 0.5833 - val_accuracy: 0.6844 - val_loss: 0.5821\n",
      "Epoch 105/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.6532 - loss: 0.5832 - val_accuracy: 0.6843 - val_loss: 0.5820\n",
      "Epoch 106/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.6534 - loss: 0.5830 - val_accuracy: 0.6843 - val_loss: 0.5819\n",
      "Epoch 107/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.6533 - loss: 0.5829 - val_accuracy: 0.6844 - val_loss: 0.5817\n",
      "Epoch 108/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.6535 - loss: 0.5827 - val_accuracy: 0.6848 - val_loss: 0.5816\n",
      "Epoch 109/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6536 - loss: 0.5825 - val_accuracy: 0.6851 - val_loss: 0.5815\n",
      "Epoch 110/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6536 - loss: 0.5825 - val_accuracy: 0.6853 - val_loss: 0.5814\n",
      "Epoch 111/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6537 - loss: 0.5824 - val_accuracy: 0.6851 - val_loss: 0.5813\n",
      "Epoch 112/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6537 - loss: 0.5822 - val_accuracy: 0.6855 - val_loss: 0.5812\n",
      "Epoch 113/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6535 - loss: 0.5821 - val_accuracy: 0.6857 - val_loss: 0.5811\n",
      "Epoch 114/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.6536 - loss: 0.5820 - val_accuracy: 0.6858 - val_loss: 0.5809\n",
      "Epoch 115/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6538 - loss: 0.5818 - val_accuracy: 0.6856 - val_loss: 0.5808\n",
      "Epoch 116/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.6537 - loss: 0.5817 - val_accuracy: 0.6857 - val_loss: 0.5807\n",
      "Epoch 117/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6539 - loss: 0.5816 - val_accuracy: 0.6860 - val_loss: 0.5806\n",
      "Epoch 118/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6539 - loss: 0.5815 - val_accuracy: 0.6860 - val_loss: 0.5805\n",
      "Epoch 119/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6539 - loss: 0.5813 - val_accuracy: 0.6862 - val_loss: 0.5804\n",
      "Epoch 120/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6540 - loss: 0.5812 - val_accuracy: 0.6865 - val_loss: 0.5803\n",
      "Completed: const_1e-4\n",
      "\n",
      "=== Running scheduler: const_1e-2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Quantization is False in data generator. This may affect model performance.\n",
      "WARNING:root:Quantization is False in data generator. This may affect model performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - accuracy: 0.6616 - loss: 3.0542 - val_accuracy: 0.5550 - val_loss: 0.6891\n",
      "Epoch 2/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7064 - val_accuracy: 0.5550 - val_loss: 0.6895\n",
      "Epoch 3/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.4161 - loss: 0.7045 - val_accuracy: 0.5550 - val_loss: 0.6893\n",
      "Epoch 4/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.4161 - loss: 0.7050 - val_accuracy: 0.5550 - val_loss: 0.6892\n",
      "Epoch 5/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.4161 - loss: 0.7056 - val_accuracy: 0.5550 - val_loss: 0.6891\n",
      "Epoch 6/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7061 - val_accuracy: 0.5550 - val_loss: 0.6890\n",
      "Epoch 7/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7065 - val_accuracy: 0.5550 - val_loss: 0.6889\n",
      "Epoch 8/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.4161 - loss: 0.7068 - val_accuracy: 0.5550 - val_loss: 0.6888\n",
      "Epoch 9/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7071 - val_accuracy: 0.5550 - val_loss: 0.6887\n",
      "Epoch 10/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.4161 - loss: 0.7073 - val_accuracy: 0.5550 - val_loss: 0.6887\n",
      "Epoch 11/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.4161 - loss: 0.7075 - val_accuracy: 0.5550 - val_loss: 0.6886\n",
      "Epoch 12/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7077 - val_accuracy: 0.5550 - val_loss: 0.6886\n",
      "Epoch 13/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7079 - val_accuracy: 0.5550 - val_loss: 0.6886\n",
      "Epoch 14/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.4161 - loss: 0.7080 - val_accuracy: 0.5550 - val_loss: 0.6885\n",
      "Epoch 15/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7081 - val_accuracy: 0.5550 - val_loss: 0.6885\n",
      "Epoch 16/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7082 - val_accuracy: 0.5550 - val_loss: 0.6885\n",
      "Epoch 17/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7083 - val_accuracy: 0.5550 - val_loss: 0.6885\n",
      "Epoch 18/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7084 - val_accuracy: 0.5550 - val_loss: 0.6885\n",
      "Epoch 19/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7084 - val_accuracy: 0.5550 - val_loss: 0.6885\n",
      "Epoch 20/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7085 - val_accuracy: 0.5550 - val_loss: 0.6885\n",
      "Epoch 21/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7085 - val_accuracy: 0.5550 - val_loss: 0.6885\n",
      "Epoch 22/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.4161 - loss: 0.7086 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 23/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7086 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 24/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.4161 - loss: 0.7086 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 25/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.4161 - loss: 0.7086 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 26/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7087 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 27/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.4161 - loss: 0.7087 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 28/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7087 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 29/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7087 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 30/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7087 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 31/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7087 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 32/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7087 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 33/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 34/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 35/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 36/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 37/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 38/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 39/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 40/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 41/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 42/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 43/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 44/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 45/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 46/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 47/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 48/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 49/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 50/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 51/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 52/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 53/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 54/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 55/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 56/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 57/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 58/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 59/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 60/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 61/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 62/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 63/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 64/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 65/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 66/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 67/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 68/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 69/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 70/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 71/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 72/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 73/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 74/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 75/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 76/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 77/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 78/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 79/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 80/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 81/120\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.4161 - loss: 0.7088 - val_accuracy: 0.5550 - val_loss: 0.6884\n",
      "Epoch 82/120\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4089 - loss: 0.7095"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('.')  # Ensure OptimizedDataGenerator4.py is discoverable\n",
    "\n",
    "import OptimizedDataGenerator4 as ODG\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ─── GPU memory growth ─────────────────────────────────────────────────────────\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# ─── Model definition ─────────────────────────────────────────────────────────\n",
    "def CreateXYProfileModel():\n",
    "    x_profile = tf.keras.Input(shape=(21, 1), name=\"x_profile\")\n",
    "    y_profile = tf.keras.Input(shape=(13, 1), name=\"y_profile\")\n",
    "    x_flat   = tf.keras.layers.Flatten(name=\"flatten_x\")(x_profile)\n",
    "    y_flat   = tf.keras.layers.Flatten(name=\"flatten_y\")(y_profile)\n",
    "    concat   = tf.keras.layers.Concatenate(name=\"concat_xy\")([x_flat, y_flat])\n",
    "    hidden1  = tf.keras.layers.Dense(64, activation=\"relu\", name=\"hidden_128\")(concat)\n",
    "    hidden2  = tf.keras.layers.Dense(16, activation=\"relu\", name=\"hidden_32\")(hidden1)\n",
    "    output   = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"output\")(hidden2)\n",
    "    return tf.keras.Model(inputs=[x_profile, y_profile], outputs=output)\n",
    "\n",
    "# ─── Data generators factory ───────────────────────────────────────────────────\n",
    "BASE_DIR       = Path(\"./filtering_records2000\")\n",
    "TRAIN_DIR      = BASE_DIR / \"tfrecords_train\"\n",
    "VALIDATION_DIR = BASE_DIR / \"tfrecords_validation\"\n",
    "\n",
    "def make_gens():\n",
    "    train_gen = ODG.OptimizedDataGenerator(\n",
    "        load_records=True,\n",
    "        tf_records_dir=str(TRAIN_DIR),\n",
    "        x_feature_description=[\"x_profile\", \"y_profile\"],\n",
    "    )\n",
    "    val_gen = ODG.OptimizedDataGenerator(\n",
    "        load_records=True,\n",
    "        tf_records_dir=str(VALIDATION_DIR),\n",
    "        x_feature_description=[\"x_profile\", \"y_profile\"],\n",
    "    )\n",
    "    return train_gen, val_gen\n",
    "\n",
    "# ─── Single‐run trainer (returns full history) ────────────────────────────────\n",
    "def train_and_evaluate(config):\n",
    "    train_gen, val_gen = make_gens()\n",
    "    steps = len(train_gen)\n",
    "    epochs = 120\n",
    "\n",
    "    model = CreateXYProfileModel()\n",
    "    callbacks = [EarlyStopping(monitor=\"val_loss\", patience=20, restore_best_weights=True)]\n",
    "\n",
    "    kind = config[\"type\"]\n",
    "    if kind == \"constant\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=config[\"lr\"])\n",
    "    elif kind == \"cosine_decay\":\n",
    "        sched = tf.keras.optimizers.schedules.CosineDecay(\n",
    "            initial_learning_rate=config[\"initial_lr\"],\n",
    "            decay_steps=steps * epochs,\n",
    "            alpha=config.get(\"alpha\", 0.0)\n",
    "        )\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=sched)\n",
    "    elif kind == \"cosine_restarts\":\n",
    "        sched = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "            initial_learning_rate=config[\"initial_lr\"],\n",
    "            first_decay_steps=(steps * epochs) // config.get(\"restarts_divisor\", 3),\n",
    "            alpha=config.get(\"alpha\", 0.0)\n",
    "        )\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=sched)\n",
    "    elif kind == \"exponential_decay\":\n",
    "        sched = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=config[\"initial_lr\"],\n",
    "            decay_steps=(steps * epochs) // config.get(\"decay_divisor\", 10),\n",
    "            decay_rate=config.get(\"decay_rate\", 0.96),\n",
    "            staircase=config.get(\"staircase\", True)\n",
    "        )\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=sched)\n",
    "    elif kind == \"polynomial_decay\":\n",
    "        sched = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "            initial_learning_rate=config[\"initial_lr\"],\n",
    "            decay_steps=steps * epochs,\n",
    "            end_learning_rate=config.get(\"end_lr\", 1e-5),\n",
    "            power=config.get(\"power\", 1.0)\n",
    "        )\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=sched)\n",
    "    elif kind == \"inverse_time_decay\":\n",
    "        sched = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "            initial_learning_rate=config[\"initial_lr\"],\n",
    "            decay_steps=(steps * epochs) // config.get(\"decay_divisor\", 10),\n",
    "            decay_rate=config.get(\"decay_rate\", 1.0),\n",
    "            staircase=config.get(\"staircase\", True)\n",
    "        )\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=sched)\n",
    "    elif kind == \"piecewise\":\n",
    "        sched = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "            boundaries=config[\"boundaries\"],\n",
    "            values=config[\"values\"]\n",
    "        )\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=sched)\n",
    "    elif kind == \"reduce_on_plateau\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=config[\"lr\"])\n",
    "        callbacks.append(ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=config.get(\"factor\", 0.5),\n",
    "            patience=config.get(\"patience\", 10),\n",
    "            verbose=1\n",
    "        ))\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown scheduler type {kind!r}\")\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    hist = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps,\n",
    "        callbacks=callbacks,\n",
    "        shuffle=False,\n",
    "        verbose=1\n",
    "    ).history\n",
    "\n",
    "    return hist\n",
    "\n",
    "# ─── Configurations including all schedulers ──────────────────────────────────\n",
    "configs = [\n",
    "    {\"name\":\"const_1e-3\",     \"type\":\"constant\",         \"lr\":1e-3},\n",
    "    {\"name\":\"const_1e-4\",     \"type\":\"constant\",         \"lr\":1e-4},\n",
    "    {\"name\":\"const_1e-2\",     \"type\":\"constant\",         \"lr\":1e-2},\n",
    "    {\"name\":\"cosine_decay\",   \"type\":\"cosine_decay\",     \"initial_lr\":1e-3, \"alpha\":0.0},\n",
    "    {\"name\":\"cosine_restarts\",\"type\":\"cosine_restarts\",  \"initial_lr\":1e-3, \"restarts_divisor\":3, \"alpha\":0.0},\n",
    "    {\"name\":\"exp_decay\",      \"type\":\"exponential_decay\",\"initial_lr\":1e-3, \"decay_rate\":0.96, \"decay_divisor\":10, \"staircase\":True},\n",
    "    {\"name\":\"poly_decay\",     \"type\":\"polynomial_decay\", \"initial_lr\":1e-3, \"end_lr\":1e-5, \"power\":2.0},\n",
    "    {\"name\":\"inv_time_decay\", \"type\":\"inverse_time_decay\",\"initial_lr\":1e-3, \"decay_rate\":1.0, \"decay_divisor\":10, \"staircase\":True},\n",
    "    {\"name\":\"piecewise\",      \"type\":\"piecewise\",        \"boundaries\":[3000,6000], \"values\":[1e-3,1e-4,1e-5]},\n",
    "    {\"name\":\"reduce_plateau\", \"type\":\"reduce_on_plateau\",\"lr\":1e-3, \"factor\":0.5, \"patience\":10},\n",
    "]\n",
    "\n",
    "# ─── Run sequentially and display progress ────────────────────────────────────\n",
    "histories = {}\n",
    "for cfg in configs:\n",
    "    name = cfg[\"name\"]\n",
    "    print(f\"\\n=== Running scheduler: {name} ===\")\n",
    "    sys.stdout.flush()\n",
    "    histories[name] = train_and_evaluate(cfg)\n",
    "    print(f\"Completed: {name}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# ─── Plot all training & validation accuracy curves ───────────────────────────\n",
    "plt.figure(figsize=(10, 6))\n",
    "for name, h in histories.items():\n",
    "    plt.plot(h['accuracy'], label=f'{name} train')\n",
    "    plt.plot(h['val_accuracy'], '--', label=f'{name} val')\n",
    "plt.title('Training & Validation Accuracy by LR Scheduler')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right', fontsize='small')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
